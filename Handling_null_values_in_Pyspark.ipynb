{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "150JCmalQliZv_RFXvBI43JLlmuLEHX2t",
      "authorship_tag": "ABX9TyOvhVQ9pwYYT4tchvDSxCjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivayogi-A/Pyspark_programming/blob/master/Handling_null_values_in_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "!ls\n",
        "\n",
        "# Initialize findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# create a spark session\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder\\\n",
        "       .appName(\"isNull & isNotNull\")\\\n",
        "       .getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQyMaSMAHuW4",
        "outputId": "100e2d85-01f2-4565-e897-6e465f372f1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.ubuntu.com (91.189.91\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.ubuntu.com (91.189.91\r                                                                                                    \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [Waiting for headers] [\r                                                                                                    \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [3 InRelease 14.2 kB/129 kB 11%] [Waiting for\r                                                                                                    \rIgn:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [3 InRelease 14.2 kB/129 kB 11%] [Connected t\r                                                                                                    \rGet:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [920 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,132 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,218 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,119 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,396 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,422 kB]\n",
            "Fetched 19.1 MB in 3s (7,016 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "drive  sample_data  spark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **isNull() and isNotNull()**\n",
        "\n",
        "isNull() function is used to check if the current expression is NULL/None or column contains a NULL/None value, if it contains it returns a boolean value True. Similarly, isNotNull() function is used to check if the current expression is NOT NULL or column contains a NOT NULL value. if it contains any value it returns True.\n",
        "\n"
      ],
      "metadata": {
        "id": "0k5t9LQpHkHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TedjJuBzHimG",
        "outputId": "4cf213b6-bfd0-47be-d04e-f4d112fa2830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------+\n",
            "| name|state|gender|\n",
            "+-----+-----+------+\n",
            "|James| null|     M|\n",
            "| Anna|   NY|     F|\n",
            "|Julia| null|  null|\n",
            "+-----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create Data Frame\n",
        "\n",
        "data = [\n",
        "    (\"James\",None,\"M\"),\n",
        "    (\"Anna\",\"NY\",\"F\"),\n",
        "    (\"Julia\",None,None)\n",
        "  ]\n",
        "\n",
        "columns = [\"name\",\"state\",\"gender\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**isNull():** The function returns all the rows where cretain columns on which we apply this function contains null values.\n",
        "\n",
        "\n",
        "Syntax of isNull()\n",
        "\n",
        "* *Column.isNull()*\n",
        "\n",
        "\n",
        "* *pyspark.sql.functions.isnull(col)*\n",
        "\n",
        "\n",
        "**PySpark Column.isNull() Usage with Examples**\\\n",
        "To select rows that have a null value on a selected column use filter() with isNULL()"
      ],
      "metadata": {
        "id": "W20j48XzWR48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.state.isNull()).show()"
      ],
      "metadata": {
        "id": "OoXF2jbbIq7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab732174-7d78-44c0-a187-0d179d75f35c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------+\n",
            "| name|state|gender|\n",
            "+-----+-----+------+\n",
            "|James| null|     M|\n",
            "|Julia| null|  null|\n",
            "+-----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can also be written in the below format and also we create a new dtaframe with the filtered records."
      ],
      "metadata": {
        "id": "AalkH8rAaSvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df2 = df.filter(col(\"State\").isNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s6f9iWHXir0",
        "outputId": "2e9e45f4-5d11-4433-c656-7679f94aedef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------+\n",
            "| name|state|gender|\n",
            "+-----+-----+------+\n",
            "|James| null|     M|\n",
            "|Julia| null|  null|\n",
            "+-----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Multiple Conditions**\\\n",
        "To filter rows with NULL values on multiple columns, use either AND or & operator.\n",
        "\n",
        "Below we filter the records where both **State** and **gender** are null."
      ],
      "metadata": {
        "id": "7vpUCw5rbyWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.filter(col(\"state\").isNull() & col(\"gender\").isNull())\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIo1n6jxaQ9O",
        "outputId": "af2b7841-4a35-40af-a604-a343c4e5ef48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------+\n",
            "| name|state|gender|\n",
            "+-----+-----+------+\n",
            "|Julia| null|  null|\n",
            "+-----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark isNotNull()\n",
        "\n",
        "PySpark isNotNull() returns all the rows where there is no null values.\n",
        "\n",
        "\n",
        "Syntax of isNotNull()\n",
        "* *Column.isNotNull()*\n",
        "\n",
        "The below example uses PySpark isNotNull() function from Column class to check if a column has a NOT NULL value.\n",
        "\n"
      ],
      "metadata": {
        "id": "EVtQR42gcbrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.state.isNotNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8j5sgL9cQv2",
        "outputId": "31176783-7b17-4564-b8d5-5ac001352ec4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------+\n",
            "|name|state|gender|\n",
            "+----+-----+------+\n",
            "|Anna|   NY|     F|\n",
            "+----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df.filter(col(\"state\").isNotNull())\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9olkpB_sdoTt",
        "outputId": "ec201e8f-f629-47e6-da3a-426d28aaca75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------+\n",
            "|name|state|gender|\n",
            "+----+-----+------+\n",
            "|Anna|   NY|     F|\n",
            "+----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropping rows with Null values - Dropna()\n",
        "\n",
        "DataFrame/Dataset has a variable **na** which is an instance of class DataFrameNaFunctions hence, you should be using **na** variable on DataFrame to use drop().\n",
        "\n",
        "DataFrameNaFunctions class also have method **fill()** to replace NULL values with empty string on PySpark DataFrame"
      ],
      "metadata": {
        "id": "BsN14YGaGlVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example: create a dataframe by reading a file small_zipcode.csv\n",
        "\n",
        "zp_df = spark.read\\\n",
        "            .format(\"csv\")\\\n",
        "            .option(\"Header\",\"True\")\\\n",
        "            .option(\"inferschema\",\"True\")\\\n",
        "            .load(\"/content/drive/MyDrive/Colab_Notebooks/Datasets/small_zipcode.csv\")\n",
        "zp_df.show()\n"
      ],
      "metadata": {
        "id": "wWIBgwO7d2Fm",
        "outputId": "0cd02f7b-cfac-4a9d-bfb2-b54fa69d5189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               null|   PR|     30100|\n",
            "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|      null|\n",
            "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               null|   TX|      null|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This yields the above output. If you notice, column name, city, and population have null values.\n",
        "\n",
        "As you see above DataFrame most of the rows have NULL values except record with id=4. Now, let’s see how to drop or remove rows with null values on DataFrame.\n",
        "\n",
        "By default drop() without arguments remove all rows that have null values on any column of DataFrame."
      ],
      "metadata": {
        "id": "Ezhlod7nQD5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.dropna().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_FFGxkSPQ7s",
        "outputId": "30ce61ed-b131-46e2-98ce-8fdeabf55598"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+-----------------+-----+----------+\n",
            "| id|zipcode|  type|             city|state|population|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|  4|  76166|UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This removes all rows with null values and returns the clean DataFrame with id=4 where it doesn’t have any NULL values.\n",
        "\n",
        "Alternatively you can also get same result with dropna:(\"any\")."
      ],
      "metadata": {
        "id": "98-lrRzuRkS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.dropna(\"any\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi-MXpWPRG4N",
        "outputId": "7d8dc47c-63ff-4f97-8ee7-4a3d985f4f7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+-----------------+-----+----------+\n",
            "| id|zipcode|  type|             city|state|population|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|  4|  76166|UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Below example drops all rows that has NULL values on all columns. Our DataFrame doesn’t have null values on all rows hence below examples returns all rows."
      ],
      "metadata": {
        "id": "fkb743IiRpQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.dropna(\"all\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjAG1RXWRbXm",
        "outputId": "cbec9fc6-b567-432a-d2f7-98aab28f5deb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               null|   PR|     30100|\n",
            "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|      null|\n",
            "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               null|   TX|      null|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop Rows with NULL Values on Selected Columns**\\\n",
        "In order to remove Rows with NULL values on selected columns of PySpark DataFrame, use dropna(columns:Seq[String]) or dropna(columns:Array[String]). To these functions pass the names of the columns you wanted to check for NULL values to delete rows."
      ],
      "metadata": {
        "id": "ZZNyahRVR6j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.dropna(subset = ['type']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtotnLacR13-",
        "outputId": "dad5a6a8-d545-4e6f-d44a-0f61f61c67a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-----------------+-----+----------+\n",
            "| id|zipcode|    type|             city|state|population|\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "|  1|    704|STANDARD|             null|   PR|     30100|\n",
            "|  4|  76166|  UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|             null|   TX|      null|\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above example it dropped only those rows where **type** column is null.\n",
        "\n",
        "same way we can apply condition for multiple columns by mentioning the column names in subset as comma seperated values."
      ],
      "metadata": {
        "id": "zPc1fU2tSjJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.dropna(subset = ['type','population',]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7FxfguWSc3a",
        "outputId": "ea6ca087-4910-4238-c202-b2667f62a7b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-----------------+-----+----------+\n",
            "| id|zipcode|    type|             city|state|population|\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "|  1|    704|STANDARD|             null|   PR|     30100|\n",
            "|  4|  76166|  UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replacing null values with a delfault value in Pyspark -fillna()\n",
        "\n",
        "In PySpark,fillna() from DataFrame class or fill() from DataFrameNaFunctions is used to replace NULL/None values on all or selected multiple columns with either zero(0), empty string, space, or any constant literal values.\n",
        "\n",
        "While working on data cleaning we may need to replace the null values as one of the preliminary step. We can use the below method to do the same.\n",
        "\n",
        "\n",
        "\n",
        "**PySpark fillna() & fill() Syntax**\\\n",
        "PySpark provides DataFrame.fillna() and DataFrameNaFunctions.fill() to replace NULL/None values. These two are aliases of each other and returns the same results.\n",
        "\n",
        "syntax:\\\n",
        "*fillna(value, subset=None)*\\\n",
        "*fill(value, subset=None)*\n",
        "\n",
        "\n",
        "**value** – Value should be the data type of int, long, float, string, or dict. Value specified here will be replaced with NULL/None values.\n",
        "\n",
        "**subset** – This is optional, when used it should be the subset of the column names where you wanted to replace NULL/None values."
      ],
      "metadata": {
        "id": "DXhAhUE5TbcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.fillna(value = 0).show()\n",
        "zp_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ww3N9q0TKIw",
        "outputId": "26696400-150b-4dd0-9466-615b9a95a3ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               null|   PR|     30100|\n",
            "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n",
            "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               null|   TX|         0|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- zipcode: integer (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- population: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note in the above example the value null was replaced with only in popluation column as the data type of it is an integer.\n",
        "\n",
        "**PySpark Replace Null/None Value with Empty String**\n",
        "\n"
      ],
      "metadata": {
        "id": "1nngBHiwWpxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.fillna(\" \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDL1ou5WnFU",
        "outputId": "d791f03e-e381-4984-e0d4-b29b155d9606"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|                   |   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|                   |   TX|      null|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s replace NULLs on specific columns, below example replace a column type with an empty string and a column city with the value “unknown”."
      ],
      "metadata": {
        "id": "TBQiNHq1YfRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.fillna(\"unknown\",['type'])\\\n",
        "      .fillna(\" \",subset = ['city'])\\\n",
        "      .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwr4P3rjYYPd",
        "outputId": "a5651e5d-75c8-4f29-b28f-6db53ad14885"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|                   |   PR|     30100|\n",
            "|  2|    704| unknown|PASEO COSTA DEL SUR|   PR|      null|\n",
            "|  3|    709| unknown|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|                   |   TX|      null|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, write the above statement by using the terms in a form of dictionary as below"
      ],
      "metadata": {
        "id": "kPoHUCIUZXVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zp_df.fillna({\"city\": \"unknown\", \"type\": \"\"}) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvk73fM9Yzcc",
        "outputId": "c938c6e7-1cc7-4225-b8a4-07ece65c9a80"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|            unknown|   TX|      null|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}